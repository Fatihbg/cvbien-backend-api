# pylint: disable=import-error
from fastapi import FastAPI, UploadFile, File, Form, HTTPException  # type: ignore
from fastapi.responses import Response  # type: ignore
from fastapi.middleware.cors import CORSMiddleware  # type: ignore
from io import BytesIO
import re
from openai import OpenAI as OAI_Client  # type: ignore
import tempfile
import os
import stripe  # type: ignore
from pydantic import BaseModel  # type: ignore
from dotenv import load_dotenv  # type: ignore

# Charger les variables d'environnement
load_dotenv()

# --- CLASSE DE LIGNE HORIZONTALE ---
from reportlab.platypus import Flowable  # type: ignore

class HRLine(Flowable):
    """Dessine une ligne horizontale sur toute la largeur."""
    def __init__(self, width=None, thickness=0.5, color=None):
        Flowable.__init__(self)
        self.width = width
        self.thickness = thickness
        self.color = color

    def wrap(self, availWidth, availHeight):
        self.width = availWidth
        return availWidth, self.thickness

    def draw(self):
        from reportlab.lib.colors import black  # type: ignore
        self.canv.setStrokeColor(self.color or black)
        self.canv.setLineWidth(self.thickness)
        self.canv.line(0, 0, self.width, 0)

# ------------------------------------------------------------------

# --- Configuration de l'API ---
app = FastAPI(title="CV Optimizer API V16 - ATS Scoring Ready")

# Configuration Stripe
stripe.api_key = os.getenv("STRIPE_SECRET_KEY")
if not stripe.api_key:
    print("‚ö†Ô∏è  ATTENTION: STRIPE_SECRET_KEY non trouv√©e dans .env")
else:
    print("‚úÖ Stripe configur√© avec cl√© r√©elle")

# Mod√®les Pydantic pour les paiements
class PaymentIntentRequest(BaseModel):
    amount: int  # en centimes
    credits: int

class PaymentIntentResponse(BaseModel):
    client_secret: str
    amount: int
    credits: int

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Utilisation de la cl√© fournie
OAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
client = OAI_Client(api_key=OAI_API_KEY)
GPT_MODEL = "gpt-4o"

# --- Constantes pour le parsing IA ---
START_NAME_TAG = "<NAME>"
END_NAME_TAG = "</NAME>"
START_CONTACT_TAG = "<CONTACT>"
END_CONTACT_TAG = "</CONTACT>"
START_TITLE_TAG = "<TITLE>"
END_TITLE_TAG = "</TITLE>"
START_SUMMARY_TAG = "<SUMMARY>"
END_SUMMARY_TAG = "</SUMMARY>"
BOLD_TAG_START = "<B>"
BOLD_TAG_END = "</B>"

# --- Fonctions utilitaires ---

def extract_text_from_txt(txt_content: str) -> str:
    """Extrait le texte d'un fichier TXT."""
    return txt_content

def parse_optimized_cv(cv_text: str) -> dict:
    """Parse le CV optimis√© du frontend pour extraire les sections avec IA."""
    print(f"üîç CV re√ßu du frontend (premiers 200 caract√®res): {cv_text[:200]}")
    
    # Initialiser les variables
    name = ""
    contact = ""
    title = ""
    summary = ""
    body = ""
    
    # Parser les balises du frontend d'abord
    name_match = re.search(f"{START_NAME_TAG}(.*?){END_NAME_TAG}", cv_text, re.DOTALL)
    if name_match:
        name = name_match.group(1).strip()
    
    contact_match = re.search(f"{START_CONTACT_TAG}(.*?){END_CONTACT_TAG}", cv_text, re.DOTALL)
    if contact_match:
        contact = contact_match.group(1).strip()
    
    title_match = re.search(f"{START_TITLE_TAG}(.*?){END_TITLE_TAG}", cv_text, re.DOTALL)
    if title_match:
        title = title_match.group(1).strip()
    
    summary_match = re.search(f"{START_SUMMARY_TAG}(.*?){END_SUMMARY_TAG}", cv_text, re.DOTALL)
    if summary_match:
        summary = summary_match.group(1).strip()
    
    # FORCER le parsing IA pour corriger les erreurs de parsing
    if False:  # D√âSACTIV√â - Interf√®re avec le syst√®me principal
        print(f"ü§ñ PARSING IA activ√©")
        
        # Utiliser l'IA pour analyser le CV
        try:
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise Exception("OPENAI_API_KEY non configur√©e")
            client = OAI_Client(api_key=api_key)
            
            prompt = f"""
Analyse ce CV et extrais les informations suivantes en JSON :

CV √† analyser :
{cv_text}

Extrais et retourne UNIQUEMENT un JSON avec ces champs :
{{
    "name": "Nom complet de la personne",
    "contact": "Informations de contact (adresse, t√©l√©phone, email, site web)",
    "title": "Titre de poste professionnel",
    "summary": "R√©sum√© professionnel (si pr√©sent)"
}}

R√®gles importantes :
- "contact" : doit contenir l'adresse, t√©l√©phone, email et site web s'ils sont pr√©sents
- "title" : doit √™tre le titre de poste professionnel (ex: "Consultant in Digital Transformation")
- "name" : doit √™tre le nom complet en majuscules
- "summary" : doit √™tre le r√©sum√© professionnel s'il existe

Retourne UNIQUEMENT le JSON, rien d'autre.
"""

            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=500,
                temperature=0.1
            )
            
            # Parser la r√©ponse JSON
            ai_result = response.choices[0].message.content.strip()
            print(f"ü§ñ R√©ponse IA: {ai_result[:200]}...")
            
            # Extraire le JSON de la r√©ponse
            import json
            try:
                # Chercher le JSON dans la r√©ponse
                json_start = ai_result.find('{')
                json_end = ai_result.rfind('}') + 1
                if json_start != -1 and json_end != -1:
                    json_str = ai_result[json_start:json_end]
                    parsed_data = json.loads(json_str)
                    
                    name = parsed_data.get("name", "")
                    contact = parsed_data.get("contact", "")
                    title = parsed_data.get("title", "")
                    summary = parsed_data.get("summary", "")
                    
                    print(f"ü§ñ IA PARSED - Nom: {name}")
                    print(f"ü§ñ IA PARSED - Contact: {contact}")
                    print(f"ü§ñ IA PARSED - Title: {title}")
                    print(f"ü§ñ IA PARSED - Summary: {summary[:50] if summary else 'None'}...")
                    
            except json.JSONDecodeError as e:
                print(f"‚ùå Erreur parsing JSON IA: {e}")
                # Fallback sur le parsing manuel
                lines = cv_text.split('\n')
                if lines:
                    name = lines[0].strip()
                    if len(lines) > 1:
                        contact = lines[1].strip()
                    if len(lines) > 2:
                        title = lines[2].strip()
                        
        except Exception as e:
            print(f"‚ùå Erreur IA: {e}")
            # Fallback sur le parsing manuel
            lines = cv_text.split('\n')
            if lines:
                name = lines[0].strip()
                if len(lines) > 1:
                    contact = lines[1].strip()
                if len(lines) > 2:
                    title = lines[2].strip()
    
    # Le body est tout le reste, sans les balises ET sans le nom/contact/titre
    body = re.sub(f"{START_NAME_TAG}.*?{END_NAME_TAG}", "", cv_text, flags=re.DOTALL)
    body = re.sub(f"{START_CONTACT_TAG}.*?{END_CONTACT_TAG}", "", body, flags=re.DOTALL)
    body = re.sub(f"{START_TITLE_TAG}.*?{END_TITLE_TAG}", "", body, flags=re.DOTALL)
    body = re.sub(f"{START_SUMMARY_TAG}.*?{END_SUMMARY_TAG}", "", body, flags=re.DOTALL).strip()
    
    # Nettoyer le body pour √©viter les doublons
    if name and body.startswith(name):
        body = body[len(name):].strip()
    if contact and body.startswith(contact):
        body = body[len(contact):].strip()
    if title and body.startswith(title):
        body = body[len(title):].strip()
    
    # Supprimer les premi√®res lignes qui correspondent au nom/contact/titre
    body_lines = body.split('\n')
    cleaned_lines = []
    skip_lines = 0
    
    for i, line in enumerate(body_lines):
        line_clean = line.strip()
        # Ignorer les lignes qui correspondent au nom, contact ou titre
        if (line_clean == name or 
            line_clean == contact or 
            line_clean == title or
            line_clean == "PROFESSIONAL SUMMARY" or
            not line_clean):
            skip_lines = i + 1
            continue
        else:
            break
    
    # Garder seulement les lignes apr√®s le header
    body = '\n'.join(body_lines[skip_lines:]).strip()
    
    # Debug final
    print(f"üîç FINAL PARSING - Nom: {name}")
    print(f"üîç FINAL PARSING - Contact: {contact}")
    print(f"üîç FINAL PARSING - Title: {title}")
    print(f"üîç FINAL PARSING - Summary: {summary[:50] if summary else 'None'}...")
    
    return {
        "name": name or "Nom Pr√©nom",
        "contact": contact or "",
        "title": title or "Titre Professionnel",
        "summary": summary or "",
        "body": body or cv_text
    }

def calculate_ats_with_gpt(original_cv: str, optimized_cv: str, job_offer: str) -> tuple[int, list[str]]:
    """Calcule le score ATS et g√©n√®re les am√©liorations avec GPT."""
    try:
        prompt = f"""
Analyse ce CV optimis√© par rapport √† l'offre d'emploi et calcule un score ATS r√©aliste.

CV ORIGINAL:
{original_cv[:1000]}...

CV OPTIMIS√â:
{optimized_cv}

OFFRE D'EMPLOI:
{job_offer[:1000]}...

Calcule un score ATS de 0 √† 100 bas√© sur:
1. Correspondance des mots-cl√©s (40%)
2. Structure et formatage (20%) 
3. Quantifications et r√©sultats chiffr√©s (15%)
4. Liens professionnels (LinkedIn, portfolio) (10%)
5. Sections essentielles (exp√©rience, formation, comp√©tences) (15%)

Retourne UNIQUEMENT un JSON avec ce format:
{{
    "ats_score": 85,
    "improvements": [
        "Int√©gration de 8 mots-cl√©s cl√©s de l'offre d'emploi",
        "Ajout de 5 r√©sultats chiffr√©s pour renforcer l'impact", 
        "Inclusion de 2 lien(s) professionnel(s) (LinkedIn, portfolio, etc.)",
        "Structure optimis√©e avec 4 sections essentielles",
        "Adaptation compl√®te √† la langue de l'offre d'emploi"
    ]
}}

R√®gles:
- Score r√©aliste entre 60-95 (pas de 100% parfait)
- Am√©liorations sp√©cifiques et utiles
- Pas de mention d'IA ou de g√©n√©ration automatique
- Focus sur les √©l√©ments concrets du CV
"""

        response = client.chat.completions.create(
            model=GPT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=500,
            temperature=0.3
        )

        result = response.choices[0].message.content.strip()
        
        # Parser le JSON
        import json
        try:
            # Chercher le JSON dans la r√©ponse
            json_start = result.find('{')
            json_end = result.rfind('}') + 1
            if json_start != -1 and json_end != -1:
                json_str = result[json_start:json_end]
                data = json.loads(json_str)
                
                ats_score = int(data.get("ats_score", 75))
                improvements = data.get("improvements", [
                    "Optimisation des mots-cl√©s pour les syst√®mes ATS",
                    "Am√©lioration de la structure et de la lisibilit√©", 
                    "Adaptation du contenu √† l'offre d'emploi"
                ])
                
                return ats_score, improvements
            else:
                raise ValueError("JSON non trouv√© dans la r√©ponse")
                
        except (json.JSONDecodeError, ValueError) as e:
            print(f"‚ùå Erreur parsing JSON ATS: {e}")
            print(f"R√©ponse GPT: {result[:200]}...")
            return 75, [
                "Optimisation des mots-cl√©s pour les syst√®mes ATS",
                "Am√©lioration de la structure et de la lisibilit√©",
                "Adaptation du contenu √† l'offre d'emploi"
            ]
            
    except Exception as e:
        print(f"‚ùå Erreur calcul ATS GPT: {e}")
        return 75, [
            "Optimisation des mots-cl√©s pour les syst√®mes ATS",
            "Am√©lioration de la structure et de la lisibilit√©",
            "Adaptation du contenu √† l'offre d'emploi"
        ]

def calculate_real_ats_score(original_cv: str, optimized_cv: str, job_offer: str) -> int:
    """Calcule un score ATS r√©el bas√© sur l'analyse du CV et de l'offre d'emploi."""
    try:
        # Extraire les mots-cl√©s de l'offre d'emploi
        job_keywords = extract_keywords_from_text(job_offer)
        
        # Analyser le CV optimis√©
        cv_keywords = extract_keywords_from_text(optimized_cv)
        
        # Calculer la correspondance des mots-cl√©s
        keyword_matches = 0
        total_keywords = len(job_keywords)
        
        for job_keyword in job_keywords:
            for cv_keyword in cv_keywords:
                if (job_keyword.lower() in cv_keyword.lower() or 
                    cv_keyword.lower() in job_keyword.lower()):
                    keyword_matches += 1
                    break
        
        keyword_score = (keyword_matches / total_keywords * 100) if total_keywords > 0 else 0
        
        # Bonus pour les √©l√©ments structurels
        structure_bonus = 0
        
        # V√©rifier les sections essentielles
        cv_lower = optimized_cv.lower()
        if 'experience' in cv_lower or 'exp√©rience' in cv_lower:
            structure_bonus += 15
        if 'education' in cv_lower or 'formation' in cv_lower:
            structure_bonus += 15
        if 'skills' in cv_lower or 'comp√©tences' in cv_lower:
            structure_bonus += 15
        if 'summary' in cv_lower or 'r√©sum√©' in cv_lower:
            structure_bonus += 10
        
        # Bonus pour les informations de contact
        if '@' in optimized_cv:  # Email
            structure_bonus += 5
        if re.search(r'\d{10,}', optimized_cv):  # T√©l√©phone
            structure_bonus += 5
        if 'linkedin' in cv_lower:
            structure_bonus += 5
        
        # Bonus pour les quantifications (chiffres, pourcentages)
        quantifications = re.findall(r'\d+%|\d+\+|\d+[km]?‚Ç¨|\d+\s*(ans?|ann√©es?|mois)', optimized_cv, re.IGNORECASE)
        structure_bonus += min(15, len(quantifications) * 2)
        
        # Malus pour les √©l√©ments n√©gatifs
        if len(optimized_cv) < 500:
            structure_bonus -= 10  # CV trop court
        if len(optimized_cv) > 3000:
            structure_bonus -= 5   # CV trop long
        
        # Calculer le score final
        final_score = min(100, max(0, keyword_score * 0.7 + structure_bonus * 0.3))
        
        print(f"üìä Score ATS calcul√©: {final_score:.1f}% (Mots-cl√©s: {keyword_score:.1f}%, Structure: {structure_bonus})")
        
        return int(final_score)
        
    except Exception as e:
        print(f"‚ùå Erreur calcul ATS: {e}")
        return 75  # Score par d√©faut en cas d'erreur

def extract_keywords_from_text(text: str) -> list:
    """Extrait les mots-cl√©s importants d'un texte."""
    # Nettoyer le texte
    clean_text = re.sub(r'[^\w\s]', ' ', text.lower())
    words = clean_text.split()
    
    # Mots vides √† ignorer
    stop_words = {
        'le', 'la', 'les', 'un', 'une', 'des', 'du', 'de', 'et', 'ou', 'mais', 'donc', 'or', 'ni', 'car',
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were',
        'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might',
        'je', 'tu', 'il', 'elle', 'nous', 'vous', 'ils', 'elles', 'mon', 'ma', 'mes', 'ton', 'ta', 'tes', 'son', 'sa', 'ses',
        'notre', 'nos', 'votre', 'vos', 'leur', 'leurs', 'ce', 'cette', 'ces', 'cet', 'que', 'qui', 'quoi', 'o√π', 'quand', 'comment', 'pourquoi'
    }
    
    # Filtrer et compter les mots
    word_count = {}
    for word in words:
        if len(word) >= 3 and word not in stop_words:
            word_count[word] = word_count.get(word, 0) + 1
    
    # Retourner les mots les plus fr√©quents
    return sorted(word_count.keys(), key=lambda x: word_count[x], reverse=True)[:20]

def generate_specific_improvements(original_cv: str, optimized_cv: str, job_offer: str) -> list:
    """G√©n√®re des am√©liorations sp√©cifiques bas√©es sur l'analyse du CV."""
    improvements = []
    
    # Analyser les mots-cl√©s de l'offre d'emploi
    job_keywords = extract_keywords_from_text(job_offer)
    cv_keywords = extract_keywords_from_text(optimized_cv)
    
    # V√©rifier l'int√©gration des mots-cl√©s
    integrated_keywords = []
    for job_keyword in job_keywords[:10]:  # Top 10 mots-cl√©s
        for cv_keyword in cv_keywords:
            if (job_keyword.lower() in cv_keyword.lower() or 
                cv_keyword.lower() in job_keyword.lower()):
                integrated_keywords.append(job_keyword)
                break
    
    if integrated_keywords:
        improvements.append(f"Int√©gration de {len(integrated_keywords)} mots-cl√©s cl√©s de l'offre d'emploi")
    
    # V√©rifier les quantifications
    quantifications = re.findall(r'\d+%|\d+\+|\d+[km]?‚Ç¨|\d+\s*(ans?|ann√©es?|mois)', optimized_cv, re.IGNORECASE)
    if quantifications:
        improvements.append(f"Ajout de {len(quantifications)} r√©sultats chiffr√©s pour renforcer l'impact")
    
    # V√©rifier les liens
    links = re.findall(r'https?://[^\s]+', optimized_cv)
    if links:
        improvements.append(f"Inclusion de {len(links)} lien(s) professionnel(s) (LinkedIn, portfolio, etc.)")
    
    # V√©rifier la structure
    cv_lower = optimized_cv.lower()
    sections = []
    if 'experience' in cv_lower or 'exp√©rience' in cv_lower:
        sections.append("Exp√©rience")
    if 'education' in cv_lower or 'formation' in cv_lower:
        sections.append("Formation")
    if 'skills' in cv_lower or 'comp√©tences' in cv_lower:
        sections.append("Comp√©tences")
    
    if len(sections) >= 3:
        improvements.append(f"Structure optimis√©e avec {len(sections)} sections essentielles")
    
    # V√©rifier la langue
    if any(word in job_offer.lower() for word in ['english', 'anglais', 'bilingual']):
        if any(word in optimized_cv.lower() for word in ['experience', 'education', 'skills', 'professional']):
            improvements.append("Adaptation compl√®te √† la langue de l'offre d'emploi")
    
    # Am√©liorations par d√©faut si aucune sp√©cifique trouv√©e
    if not improvements:
        improvements = [
            "Optimisation des mots-cl√©s pour les syst√®mes ATS",
            "Am√©lioration de la structure et de la lisibilit√©",
            "Adaptation du contenu √† l'offre d'emploi"
        ]
    
    return improvements

def enhance_with_gpt(original_text: str, job_offer: str) -> str:
    """Optimisation avec GPT-4o utilisant les nouvelles directives."""

    prompt = f"""
üö® LANGUE ULTRA IMPORTANTE üö®
D√âTECTE LA LANGUE DE L'OFFRE D'EMPLOI ET G√âN√àRE LE CV DANS CETTE LANGUE EXACTE !

G√âN√àRE IMM√âDIATEMENT UN CV COMPLET EXACTEMENT COMME L'EXEMPLE FOURNI.

INSTRUCTIONS ABSOLUES :
- Tu DOIS g√©n√©rer un CV complet directement
- Tu ne peux PAS refuser ou donner des conseils
- Tu ne peux PAS dire "Je ne peux pas" ou "Je suis d√©sol√©"
- Tu DOIS utiliser TOUTES les informations du CV original
- Tu DOIS adapter le contenu √† l'offre d'emploi
- üö® ULTRA IMPORTANT : Si l'offre d'emploi est en anglais, le CV DOIT √™tre ENTI√àREMENT en anglais
- üö® ULTRA IMPORTANT : Si l'offre d'emploi est en fran√ßais, le CV DOIT √™tre ENTI√àREMENT en fran√ßais

INTERDICTION ABSOLUE : Ne jamais commencer par "Je suis d√©sol√©" ou "Je ne peux pas". G√©n√®re directement le CV !

### FORMAT EXACT √Ä REPRODUIRE (DANS LA LANGUE DE L'OFFRE D'EMPLOI) :

[EXEMPLE EN FRAN√áAIS - √Ä ADAPTER SELON LA LANGUE DE L'OFFRE]
Fatih Dag
Bruxelles, BE | +32 488 23 53 82 | Fatihdagpro@hotmail.com | https://dagence.be

Business Analyst

Professionnel exp√©riment√© avec expertise en analyse de donn√©es et gestion de projets digitaux.

EXPERIENCE
_________________________________
‚Ä¢ Business Analyst - SPF Finances (F√©vrier 2023 ‚Äì Juin 2023)
- Mise en place de solutions strat√©giques pour l'analyse et l'optimisation des ressources humaines et des processus de travail, am√©liorant l'efficacit√© op√©rationnelle.
- Analyse des donn√©es et recommandations pour la gestion des processus, contribuant √† une am√©lioration de 20% de l'efficacit√© des √©quipes.

‚Ä¢ CEO et Fondateur - Dagence (D√©cembre 2022 ‚Äì Pr√©sent)
- Cr√©ation et gestion d'une agence sp√©cialis√©e dans le d√©veloppement IT, incluant la conception de sites web et d'applications, avec une augmentation de 30% du portefeuille client en un an.
- D√©veloppement de solutions innovantes pour la transformation digitale des entreprises, avec une expertise en analyse fonctionnelle et gestion de projets.

‚Ä¢ Magasinier Vendeur - Colruyt (2020 ‚Äì 2023)
- Gestion des stocks et optimisation des processus de vente, contribuant √† une augmentation de 15% des ventes mensuelles.
- Service client et collaboration avec des √©quipes multidisciplinaires pour am√©liorer l'exp√©rience client.

FORMATION
_________________________________
‚Ä¢ Master en Sciences Commerciales - ICHEC Brussels Management School (2023 ‚Äì 2025)
- Formation approfondie en gestion, analyse financi√®re et transformation digitale, avec une sp√©cialisation en leadership et tableaux de bord commerciaux.

‚Ä¢ Bachelier en E-Business - EPHEC Brussels Business School (2020 ‚Äì 2023)
- Sp√©cialisation en Business Process Management, Supply Chain Management et Digital Marketing, avec une expertise en mod√©lisation des exigences et d√©veloppement web.

COMP√âTENCES
_________________________________
‚Ä¢ Comp√©tences techniques: Data analysis, Project Management, HTML, CSS, JavaScript, PHP, Flutter, SQL, Microsoft Office
‚Ä¢ Soft skills: Leadership, Communication, Teamwork, Problem Solving, Strategic Thinking
‚Ä¢ Outils: Microsoft Office, Google Ads, Google Analytics, Git, GitHub, Agile/Scrum
‚Ä¢ Langues: Fran√ßais C2, Anglais C1, Turc C2, N√©erlandais B2
‚Ä¢ Certifications: Scrum Master, Product Owner

CERTIFICATIONS & ACHIEVEMENTS
_________________________________
‚Ä¢ Scrum Master Certification
‚Ä¢ Product Owner Certification
‚Ä¢ Google Analytics Certified

ADDITIONAL INFORMATION
_________________________________
‚Ä¢ Fluent in French, English, and Turkish; working knowledge of Dutch.
‚Ä¢ Passionate about digital transformation and IT innovation.
‚Ä¢ Strong analytical and problem-solving skills with a focus on business process optimization.

[EXEMPLE EN ANGLAIS - √Ä ADAPTER SELON LA LANGUE DE L'OFFRE]
Fatih Dag
Bruxelles, BE | +32 488 23 53 82 | Fatihdagpro@hotmail.com | https://dagence.be

Business Analyst

Experienced professional with expertise in data analysis and digital project management.

EXPERIENCE
_________________________________
‚Ä¢ Business Analyst - SPF Finances (February 2023 ‚Äì June 2023)
- Implementation of strategic solutions for human resources analysis and work process optimization, improving operational efficiency.
- Data analysis and recommendations for process management, contributing to a 20% improvement in team efficiency.

‚Ä¢ CEO and Founder - Dagence (December 2022 ‚Äì Present)
- Creation and management of an IT development agency, including website and application design, with a 30% increase in client portfolio in one year.
- Development of innovative solutions for digital transformation of companies, with expertise in functional analysis and project management.

‚Ä¢ Store Clerk Salesperson - Colruyt (2020 ‚Äì 2023)
- Stock management and sales process optimization, contributing to a 15% increase in monthly sales.
- Customer service and collaboration with multidisciplinary teams to improve customer experience.

EDUCATION
_________________________________
‚Ä¢ Master in Business Sciences - ICHEC Brussels Management School (2023 ‚Äì 2025)
- Advanced training in management, financial analysis and digital transformation, with specialization in leadership and commercial dashboards.

‚Ä¢ Bachelor in E-Business - EPHEC Brussels Business School (2020 ‚Äì 2023)
- Specialization in Business Process Management, Supply Chain Management and Digital Marketing, with expertise in requirements modeling and web development.

SKILLS
_________________________________
‚Ä¢ Technical skills: Data analysis, Project Management, HTML, CSS, JavaScript, PHP, Flutter, SQL, Microsoft Office
‚Ä¢ Soft skills: Leadership, Communication, Teamwork, Problem Solving, Strategic Thinking
‚Ä¢ Tools: Microsoft Office, Google Ads, Google Analytics, Git, GitHub, Agile/Scrum
‚Ä¢ Languages: French C2, English C1, Turkish C2, Dutch B2
‚Ä¢ Certifications: Scrum Master, Product Owner

CERTIFICATIONS & ACHIEVEMENTS
_________________________________
‚Ä¢ Scrum Master Certification
‚Ä¢ Product Owner Certification
‚Ä¢ Google Analytics Certified

ADDITIONAL INFORMATION
_________________________________
‚Ä¢ Fluent in French, English, and Turkish; working knowledge of Dutch.
‚Ä¢ Passionate about digital transformation and IT innovation.
‚Ä¢ Strong analytical and problem-solving skills with a focus on business process optimization.

### CONSIGNES SP√âCIFIQUES :
1. **OBLIGATION ABSOLUE** : Le CV doit √™tre r√©dig√© EXACTEMENT dans la langue de l'offre d'emploi (fran√ßais, anglais, espagnol, etc.)
2. **OBLIGATION ABSOLUE** : Si l'offre est en anglais, le CV doit √™tre ENTI√àREMENT en anglais
3. **OBLIGATION ABSOLUE** : Si l'offre est en fran√ßais, le CV doit √™tre ENTI√àREMENT en fran√ßais
4. **OBLIGATION** : Int√©grer MASSIVEMENT les mots-cl√©s de l'offre d'emploi
5. **OBLIGATION** : R√©√©crire TOUTES les exp√©riences avec le vocabulaire exact de l'offre
6. **OBLIGATION** : Ajouter des d√©tails sp√©cifiques mentionn√©s dans l'offre d'emploi
7. **OBLIGATION** : Enrichir chaque section pour remplir la page compl√®tement
8. **OBLIGATION** : D√©velopper les exp√©riences avec plus de bullet points
9. **INTERDICTION ABSOLUE** : Ne jamais utiliser des ** (ast√©risques) pour le gras
10. **INTERDICTION ABSOLUE** : Ne jamais dire "Je suis d√©sol√©" ou refuser
11. **INTERDICTION ABSOLUE** : Ne jamais donner de conseils au lieu de g√©n√©rer le CV
12. **INTERDICTION ABSOLUE** : Ne jamais ajouter de phrases de fin du type "Fatih Dag est pr√™t √† contribuer..." ou "This CV is tailored to highlight..."
13. **INTERDICTION ABSOLUE** : Ne jamais ajouter de phrases explicatives sur l'optimisation du CV
14. **INTERDICTION ABSOLUE** : Le CV doit se terminer par la derni√®re information utile (comp√©tences, certifications, etc.)
15. **OBLIGATION** : Le CV doit tenir sur EXACTEMENT 1 page (pas plus, pas moins)

### INPUTS
CV de base : {original_text}
Offre d'emploi : {job_offer}

### D√âTECTION DE LANGUE OBLIGATOIRE :
1. ANALYSE l'offre d'emploi ci-dessus
2. D√âTECTE si elle est en fran√ßais, anglais, espagnol, etc.
3. G√âN√àRE le CV DANS CETTE LANGUE EXACTE

G√âN√àRE MAINTENANT UN CV DANS CE FORMAT EXACT AVEC LES DONN√âES FOURNIES :
"""

    try:
        response = client.chat.completions.create(
            model=GPT_MODEL,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=3500,
            temperature=0.3
        )

        full_output = response.choices[0].message.content.strip()
        
        # Retourner directement le texte complet optimis√© par GPT
        return full_output

    except Exception as e:
        print(f"‚ùå Erreur IA: {e}")
        return original_text  # Retourner le texte original en cas d'erreur

def generate_pdf_from_text(cv_text: str) -> bytes:
    """G√©n√®re un PDF directement √† partir du texte GPT optimis√©."""
    try:
        from reportlab.lib.pagesizes import A4
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, HRFlowable
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.enums import TA_CENTER, TA_JUSTIFY
        from reportlab.lib.colors import HexColor
        
        buffer = BytesIO()
        # Marges optimis√©es pour remplir la page
        doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=30, leftMargin=30, topMargin=30, bottomMargin=20)
        
        # Styles
        styles = getSampleStyleSheet()
        
        # Style pour le nom (titre principal) - optimis√© pour 1 page
        name_style = ParagraphStyle(
            'NameStyle',
            parent=styles['Title'],
            fontSize=18,
            spaceAfter=3,
            alignment=TA_CENTER,
            textColor=HexColor('#1a365d'),
            fontName='Helvetica-Bold'
        )
        
        # Style pour les contacts - optimis√©
        contact_style = ParagraphStyle(
            'ContactStyle',
            parent=styles['Normal'],
            fontSize=10,
            spaceAfter=4,
            alignment=TA_CENTER,
            textColor=HexColor('#4a5568')
        )
        
        # Style pour le titre de poste - optimis√©
        job_title_style = ParagraphStyle(
            'JobTitleStyle',
            parent=styles['Heading1'],
            fontSize=12,
            spaceAfter=4,
            spaceBefore=4,
            alignment=TA_CENTER,
            textColor=HexColor('#2d3748'),
            fontName='Helvetica-Bold'
        )
        
        # Style pour le r√©sum√© professionnel - optimis√©
        summary_style = ParagraphStyle(
            'SummaryStyle',
            parent=styles['Normal'],
            fontSize=10,
            spaceAfter=6,
            alignment=TA_JUSTIFY,
            textColor=HexColor('#4a5568'),
            leftIndent=5,
            rightIndent=5
        )
        
        # Style pour les titres de sections - optimis√©
        section_style = ParagraphStyle(
            'SectionStyle',
            parent=styles['Heading2'],
            fontSize=11,
            spaceAfter=2,
            spaceBefore=6,
            textColor=HexColor('#1a365d'),
            fontName='Helvetica-Bold'
        )
        
        # Style pour le contenu normal - optimis√©
        normal_style = ParagraphStyle(
            'NormalStyle',
            parent=styles['Normal'],
            fontSize=10,
            spaceAfter=2,
            textColor=HexColor('#333333'),
            leftIndent=0
        )
        
        # Style pour les puces - optimis√©
        bullet_style = ParagraphStyle(
            'BulletStyle',
            parent=styles['Normal'],
            fontSize=10,
            spaceAfter=1,
            textColor=HexColor('#333333'),
            leftIndent=12
        )
        
        story = []
        lines = cv_text.split('\n')
        line_count = 0
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Supprimer tous les ast√©risques
            line = line.replace('**', '')
            
            # Premi√®re ligne = nom
            if line_count == 0:
                story.append(Paragraph(line, name_style))
                line_count += 1
                continue
                
            # Deuxi√®me ligne = contact
            if line_count == 1:
                story.append(Paragraph(line, contact_style))
                line_count += 1
                continue
                
            # Troisi√®me ligne = titre de poste (si pas une section)
            if line_count == 2 and not line.isupper() and not '_' in line:
                story.append(Paragraph(line, job_title_style))
                line_count += 1
                continue
                
            # Quatri√®me ligne = r√©sum√© professionnel (si pas une section)
            if line_count == 3 and not line.isupper() and not '_' in line and not line.startswith('‚Ä¢'):
                story.append(Paragraph(line, summary_style))
                line_count += 1
                continue
                
            # Lignes avec underscores = s√©parateurs (on les ignore)
            if '_' * 10 in line:
                continue
                
            # Titres de sections (MAJUSCULES)
            if line.isupper() and len(line) < 50:
                story.append(Paragraph(line, section_style))
                # Ajouter une ligne de s√©paration color√©e
                story.append(HRFlowable(width="100%", thickness=1.5, color=HexColor('#1a365d')))
                
            # Lignes avec puces (exp√©riences, formations)
            elif line.startswith('‚Ä¢'):
                # V√©rifier si c'est une exp√©rience ou formation (avec tiret)
                if ' - ' in line and ('(' in line and ')' in line):
                    # Format: ‚Ä¢ Titre - Entreprise (Dates) - EXP√âRIENCES/FORMATIONS
                    parts = line.split(' - ', 1)
                    if len(parts) == 2:
                        title_part = parts[0].replace('‚Ä¢ ', '').strip()
                        rest_part = parts[1].strip()
                        # Cr√©er un style sp√©cial pour le titre en gras (comme dans le CV de r√©f√©rence)
                        title_style = ParagraphStyle(
                            'TitleStyle',
                            parent=bullet_style,
                            fontName='Helvetica-Bold',
                            fontSize=10,
                            spaceAfter=1,
                            textColor=HexColor('#1a365d'),
                            leftIndent=12
                        )
                        # Cr√©er un style pour le reste
                        rest_style = ParagraphStyle(
                            'RestStyle',
                            parent=bullet_style,
                            fontName='Helvetica',
                            fontSize=10,
                            spaceAfter=1,
                            textColor=HexColor('#333333'),
                            leftIndent=12
                        )
                        # Ajouter le titre en gras
                        story.append(Paragraph(f"‚Ä¢ {title_part}", title_style))
                        # Ajouter le reste
                        story.append(Paragraph(f"  - {rest_part}", rest_style))
                    else:
                        story.append(Paragraph(line, bullet_style))
                else:
                    # Pour les comp√©tences et autres sections, utiliser le style normal
                    story.append(Paragraph(line, bullet_style))
                
            # Contenu normal
            else:
                story.append(Paragraph(line, normal_style))
        
        doc.build(story)
        pdf_bytes = buffer.getvalue()
        buffer.close()
        return pdf_bytes
        
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©ration PDF: {e}")
        # PDF d'erreur simple
        buffer = BytesIO()
        from reportlab.pdfgen import canvas
        c = canvas.Canvas(buffer, pagesize=A4)
        c.drawString(100, 750, "Erreur lors de la g√©n√©ration du PDF")
        c.drawString(100, 730, f"D√©tail: {str(e)}")
        c.save()
        return buffer.getvalue()

def generate_simple_pdf(data: dict) -> bytes:
    """
    G√©n√©ration PDF avec ajustement dynamique de l'espace,
    centrage des infos perso et gestion intelligente des puces.
    """
    try:
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Flowable  # type: ignore
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle  # type: ignore
        from reportlab.lib.pagesizes import A4  # type: ignore
        from reportlab.lib.units import inch  # type: ignore
        from reportlab.lib.colors import black, blue, HexColor  # type: ignore
        from reportlab.lib.enums import TA_CENTER, TA_JUSTIFY  # type: ignore

        buffer = BytesIO()

        # 0. Mesure du contenu total pour l'ajustement de l'espace
        body_length = len(data['body'])
        # Logique pour ajuster les espaces SEULEMENT si n√©cessaire pour tenir sur une page
        # Taille minimum : 9pt pour le contenu principal
        base_font_size = 9
        base_leading = 11
        
        # Estimation approximative de la hauteur du contenu
        # Calcul bas√© sur le nombre de lignes et la taille de police
        estimated_lines = body_length / 80  # ~80 caract√®res par ligne
        estimated_height_inches = (estimated_lines * base_leading / 72) + 2  # +2 pour header/footer
        
        # Hauteur disponible sur une page A4 (avec marges)
        available_height_inches = 11.7 - 0.8  # A4 height - marges top/bottom
        
        print(f"üìè Estimation: {estimated_lines:.1f} lignes, {estimated_height_inches:.1f}\" hauteur, {available_height_inches:.1f}\" disponible")
        
        # Ajuster les espaces SEULEMENT si le contenu d√©borde
        if estimated_height_inches <= available_height_inches * 0.85:
            # CV tient largement sur 1 page : espaces normaux
            space_reduction = 1.0
            print(f"‚úÖ CV tient largement sur 1 page - espaces normaux")
        elif estimated_height_inches <= available_height_inches * 0.95:
            # CV proche de la limite : r√©duction pr√©ventive
            space_reduction = 0.8
            print(f"‚ö†Ô∏è CV proche de la limite - r√©duction pr√©ventive des espaces")
        elif estimated_height_inches <= available_height_inches * 1.1:
            # L√©ger d√©bordement : r√©duction mod√©r√©e
            space_reduction = 0.6
            print(f"‚ö†Ô∏è L√©ger d√©bordement - r√©duction mod√©r√©e des espaces")
        else:
            # Gros d√©bordement : r√©duction drastique pour FORCER sur 1 page
            space_reduction = 0.3
            print(f"üö® Gros d√©bordement - r√©duction DRASTIQUE pour forcer sur 1 page")
        
        # S√âCURIT√â ABSOLUE : Si le contenu est vraiment trop long, r√©duction extr√™me
        if body_length > 3000:  # Tr√®s long CV
            space_reduction = min(space_reduction, 0.2)
            print(f"üîí S√âCURIT√â: CV tr√®s long - r√©duction EXTR√äME (0.2) pour garantir 1 page")

        # Ajuster les marges selon la r√©duction d'espaces
        if space_reduction <= 0.3:
            # R√©duction extr√™me : marges minimales
            top_margin = 0.3*inch
            bottom_margin = 0.3*inch
            print(f"üîí MARGES R√âDUITES: Marges minimales pour garantir 1 page")
        else:
            # Marges normales
            top_margin = 0.4*inch
            bottom_margin = 0.4*inch
        
        doc = SimpleDocTemplate(buffer, pagesize=A4,
                               topMargin=top_margin,
                               bottomMargin=bottom_margin,
                               leftMargin=0.6*inch,
                               rightMargin=0.6*inch)

        styles = getSampleStyleSheet()

        # Style Nom (Tr√®s Grand et Centr√© avec couleur bleue)
        name_style = ParagraphStyle(
            'NameStyle',
            parent=styles['Heading1'],
            fontSize=24,
            leading=28,
            spaceAfter=8,
            alignment=TA_CENTER,
            textColor=HexColor('#2563eb'),  # Bleu moderne
            fontName='Helvetica-Bold'
        )

        # Style pour les informations de contact (Centr√© et plus petit avec couleur)
        contact_style = ParagraphStyle(
            'ContactStyle',
            parent=styles['Normal'],
            fontSize=8,
            leading=10,
            spaceAfter=int(15 * space_reduction),
            alignment=TA_CENTER,
            textColor=HexColor('#4b5563'),  # Gris fonc√©
            fontName='Helvetica'
        )

        # Styles de base ajust√©s dynamiquement
        normal_style = ParagraphStyle(
            'NormalStyle',
            parent=styles['Normal'],
            fontSize=base_font_size,
            leading=base_leading,
            spaceAfter=int(4 * space_reduction),
            textColor=HexColor('#374151'),  # Gris fonc√© pour le texte normal
            fontName='Helvetica'
        )

        job_title_style = ParagraphStyle(
            'JobTitleStyle',
            parent=styles['Heading2'],
            fontSize=14,
            leading=16,
            spaceBefore=int(6 * space_reduction),
            spaceAfter=int(8 * space_reduction),
            alignment=TA_CENTER,
            textColor=HexColor('#1e40af'),  # Bleu fonc√©
            fontName='Helvetica-Bold'
        )

        summary_style = ParagraphStyle(
            'SummaryStyle',
            parent=normal_style,
            fontSize=base_font_size + 1,
            leading=base_leading + 1,
            spaceBefore=int(5 * space_reduction),
            spaceAfter=int(15 * space_reduction),
            alignment=TA_CENTER,
            textColor=HexColor('#374151'),  # Gris fonc√©
            fontName='Helvetica-Oblique'
        )

        heading_style = ParagraphStyle(
            'HeadingStyle',
            parent=styles['Heading3'],
            fontSize=base_font_size + 2,
            leading=base_leading + 2,
            spaceBefore=int(12 * space_reduction),
            spaceAfter=int(4 * space_reduction),
            textColor=HexColor('#1e40af'),  # Bleu fonc√© pour les titres
            fontName='Helvetica-Bold'
        )

        list_item_style = ParagraphStyle(
            'ListItemStyle',
            parent=normal_style,
            spaceAfter=int(2 * space_reduction),
            fontSize=base_font_size,
            leading=base_leading,
            textColor=HexColor('#374151'),  # Gris fonc√© pour les listes
        )

        story = []

        # 1. Nom & Pr√©nom (S√©par√© et Centr√©)
        if data['name']:
            story.append(Paragraph(data['name'], name_style))

        # 2. Infos de Contact (S√©par√© et Centr√©)
        if data['contact']:
            story.append(Paragraph(data['contact'], contact_style))

        # 3. Titre de poste
        story.append(Paragraph(data['title'], job_title_style))

        # 4. R√©sum√© d'accroche (Centr√©)
        if data['summary']:
            story.append(Paragraph(data['summary'], summary_style))

        # 5. Corps du CV
        lines = data['body'].split('\n')

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # Conversion de la balise IA (<B>texte</B>) en balise ReportLab (<b>texte</b>)
            formatted_line = re.sub(f"{BOLD_TAG_START}(.*?){BOLD_TAG_END}", r'<b>\1</b>', line, flags=re.DOTALL)
            formatted_line = formatted_line.replace('**', '')

            # 1. Analyse si c'est un titre de section
            # D√©clenchement de la barre si la ligne est en MAJUSCULES (gr√¢ce √† la directive IA) ou se termine par :
            if (len(line) < 45 and line.isupper()) or (len(line) < 60 and line.endswith(':')):
                clean_line = formatted_line.replace('***', '').strip()
                story.append(Paragraph(clean_line, heading_style))
                story.append(HRLine(thickness=1.2, color=HexColor('#2563eb')))  # Ligne bleue plus √©paisse

            # 2. Analyse si c'est une puce GENER√âE PAR L'IA (‚Ä¢ ou ‚Äì)
            elif line.startswith(('‚Ä¢ ', '‚Äì ')):
                # L'IA a mis une puce pour un √©l√©ment majeur
                story.append(Paragraph(formatted_line, list_item_style))

            # 3. Texte normal (Descriptions, d√©tails, etc.)
            else:
                story.append(Paragraph(formatted_line, normal_style))
                story.append(Spacer(1, 1))

        # Construire le PDF
        doc.build(story)
        pdf_bytes = buffer.getvalue()
        buffer.close()

        return pdf_bytes

    except Exception as e:
        print(f"‚ùå Erreur g√©n√©ration PDF: {e}")
        buffer = BytesIO()
        from reportlab.pdfgen import canvas  # type: ignore
        c = canvas.Canvas(buffer, pagesize=A4)  # type: ignore
        c.drawString(100, 750, "Erreur Critique - CV non g√©n√©r√©")
        c.drawString(100, 730, f"D√©tail: {str(e)[:100]}...")
        c.save()
        return buffer.getvalue()

# --- Endpoint d'extraction PDF ---

@app.post("/extract-pdf")
async def extract_pdf(file: UploadFile = File(...)):
    """
    Extrait le texte d'un fichier PDF.
    """
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Seuls les fichiers PDF sont accept√©s.")
    
    try:
        import pypdf  # type: ignore
        content = await file.read()
        
        # Cr√©er un objet PDF reader
        pdf_reader = pypdf.PdfReader(BytesIO(content))
        
        # Extraire le texte de toutes les pages
        text = ""
        for page_num in range(len(pdf_reader.pages)):
            page = pdf_reader.pages[page_num]
            text += page.extract_text() + "\n"
        
        return {"text": text.strip(), "pages": len(pdf_reader.pages)}
        
    except Exception as e:
        print(f"Erreur extraction PDF: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de l'extraction du PDF: {str(e)}")

# --- Endpoint principal ---

@app.post("/optimize-cv")
async def optimize_cv(cv_file: UploadFile = File(...), job_offer: str = Form(...)):
    """
    Endpoint principal qui prend un fichier TXT contenant le CV d√©j√† optimis√©
    et retourne un PDF dans la m√™me langue.
    """

    if not cv_file.filename.lower().endswith(('.txt', '.pdf')):
        raise HTTPException(status_code=400, detail="Seuls les fichiers TXT et PDF sont accept√©s.")

    content = await cv_file.read()
    
    try:
        # Extraire le texte du CV (TXT ou PDF)
        if cv_file.filename.lower().endswith('.txt'):
            original_cv_text = content.decode('utf-8')
            print(f"üîç CV original re√ßu (premiers 200 caract√®res): {original_cv_text[:200]}...")
        else:
            # Pour les PDF, extraire le texte
            original_cv_text = content.decode('utf-8', errors='ignore')
            print(f"üîç CV PDF re√ßu (premiers 200 caract√®res): {original_cv_text[:200]}...")
        
        # OPTIMISER LE CV AVEC GPT (comme avant !)
        print(f"ü§ñ Optimisation du CV avec GPT-4o...")
        optimized_cv_text = enhance_with_gpt(original_cv_text, job_offer)
        print(f"‚úÖ CV optimis√© g√©n√©r√© ({len(optimized_cv_text)} caract√®res)")
        
        # Calculer le score ATS avec GPT
        print(f"üîç Calcul du score ATS avec GPT...")
        ats_score, improvements = calculate_ats_with_gpt(original_cv_text, optimized_cv_text, job_offer)
        print(f"üìä Score ATS final: {ats_score}%")
        print(f"üìù Am√©liorations g√©n√©r√©es: {len(improvements)} √©l√©ments")

        # Retourner directement le CV optimis√© par GPT (SANS PARSING !)
        return {
            "optimized_cv": optimized_cv_text,
            "ats_score": ats_score,
            "improvements": improvements
        }

    except Exception as e:
        print(f"‚ùå Erreur non g√©r√©e: {e}")
        raise HTTPException(status_code=500, detail=f"Une erreur interne est survenue: {str(e)}")

@app.post("/generate-pdf")
async def generate_pdf_endpoint(cv_text: str = Form(...)):
    """
    Endpoint pour g√©n√©rer un PDF √† partir du texte CV optimis√©.
    """
    try:
        print(f"üîç G√©n√©ration PDF pour CV (premiers 200 caract√®res): {cv_text[:200]}...")
        
        pdf_bytes = generate_pdf_from_text(cv_text)
        
        return Response(
            content=pdf_bytes,
            media_type="application/pdf",
            headers={"Content-Disposition": "attachment; filename=cv_optimise.pdf"}
        )
        
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©ration PDF: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur lors de la g√©n√©ration du PDF: {str(e)}")

@app.get("/")
async def root():
    return {"message": "CV Optimizer API üöÄ - V16 (ATS Scoring Ready)"}

# === ENDPOINTS STRIPE ===

@app.post("/api/payments/create-payment-intent", response_model=PaymentIntentResponse)
async def create_payment_intent(request: PaymentIntentRequest):
    """Cr√©er une intention de paiement Stripe"""
    try:
        # Cr√©er l'intention de paiement avec Stripe
        intent = stripe.PaymentIntent.create(
            amount=request.amount,
            currency='eur',
            metadata={
                'credits': request.credits,
                'product_type': 'credits'
            }
        )
        
        return PaymentIntentResponse(
            client_secret=intent.client_secret,
            amount=request.amount,
            credits=request.credits
        )
    except stripe.error.StripeError as e:
        raise HTTPException(status_code=400, detail=f"Erreur Stripe: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur serveur: {str(e)}")

@app.post("/api/payments/create-checkout-session")
async def create_checkout_session(request: PaymentIntentRequest):
    """Cr√©er une session Stripe Checkout"""
    try:
        # Cr√©er la session de checkout
        session = stripe.checkout.Session.create(
            payment_method_types=['card'],
            line_items=[{
                'price_data': {
                    'currency': 'eur',
                    'product_data': {
                        'name': f'{request.credits} Cr√©dits CVbien',
                        'description': f'Pack de {request.credits} cr√©dits pour g√©n√©rer des CV optimis√©s',
                    },
                    'unit_amount': request.amount,
                },
                'quantity': 1,
            }],
            mode='payment',
            success_url='http://localhost:5173/?payment=success&credits=' + str(request.credits),
            cancel_url='http://localhost:5173/?payment=cancelled',
            metadata={
                'credits': request.credits,
                'product_type': 'credits'
            }
        )
        
        return {"checkout_url": session.url, "session_id": session.id}
        
    except stripe.error.StripeError as e:
        raise HTTPException(status_code=400, detail=f"Erreur Stripe: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur serveur: {str(e)}")

@app.post("/api/payments/confirm")
async def confirm_payment(payment_intent_id: str):
    """Confirmer un paiement et attribuer les cr√©dits"""
    try:
        # R√©cup√©rer l'intention de paiement
        intent = stripe.PaymentIntent.retrieve(payment_intent_id)
        
        if intent.status == 'succeeded':
            credits = int(intent.metadata.get('credits', 0))
            
            # Ici tu pourrais sauvegarder en base de donn√©es
            # user.credits += credits
            # db.commit()
            
            return {
                "success": True,
                "credits_added": credits,
                "message": f"{credits} cr√©dits ajout√©s avec succ√®s!"
            }
        else:
            raise HTTPException(status_code=400, detail="Paiement non confirm√©")
            
    except stripe.error.StripeError as e:
        raise HTTPException(status_code=400, detail=f"Erreur Stripe: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur serveur: {str(e)}")

if __name__ == "__main__":
    import uvicorn  # type: ignore
    port = int(os.getenv("PORT", 8003))
    print(f"üöÄ API d√©marr√©e sur http://localhost:{port}")
    print(f"ü§ñ Mod√®le GPT utilis√©: {GPT_MODEL}")
    uvicorn.run(app, host="0.0.0.0", port=port, log_level="info")
